#!/bin/bash

set -xe

_LANG="zh-TW"
CV="${SHARED_DIR}/data/mozilla/CommonVoice/v2.0-alpha2.0/${_LANG}"

# the *.csv on cluster have old paths
cp ${CV}/*.csv .
sed -Ei 's/snakepit/data\/ro/g' cv_${_LANG}_valid_*.csv

apt-get install -y python3-venv swig3.0
ln -s /usr/bin/swig3.0 /usr/bin/swig

# venv
python3 -m venv /tmp/venv
source /tmp/venv/bin/activate
# check HTTP_PROXY
if ! (( $( env | grep -iq "^http_proxy=" ) )); then
    source /etc/profile
fi

pip install -r <(grep -v tensorflow requirements.txt)
pip install tensorflow-gpu==1.13.0-rc2


###############################
### INSTALL KENLM + DECODER ###
###############################

python util/taskcluster.py --arch gpu --target ../tmp/native_client

pushd native_client/ctcdecode
make clean
make NUM_PROCESSES=16
pip install dist/*.whl
popd

# kenlm Dependencies
apt-get install -y build-essential cmake libboost-all-dev zlib1g-dev libbz2-dev liblzma-dev libeigen3-dev

# Install Kenlm #
wget -O - https://kheafield.com/code/kenlm.tar.gz | tar xz --no-same-owner
mkdir kenlm/build
cd kenlm/build
cmake ..
make -j `nproc`
cd ../..


###################################
### CREATE ALPHABET / LM / TRIE ###
###################################

# alphabet.txt
python util/check_characters.py \
        -csv "cv_${_LANG}_valid_train.csv","cv_${_LANG}_valid_train.csv","cv_${_LANG}_valid_train.csv" \
        -alpha \
    > ${SRC_DIR}/data/alphabet.txt

# lm.arpa
TEXT="${SHARED_DIR}/data/wikipedia/zh-tw/wiki.txt"
sed -e 's/\(.\)/\1 /g' <$TEXT >CHAR_GRAMS
kenlm/build/bin/lmplz \
    --order 2 \
    --text CHAR_GRAMS \
    --arpa lm.arpa

# lm.binary
kenlm/build/bin/build_binary \
    -a 255 \
    -q 8 trie \
    lm.arpa \
    data/lm/lm.binary

# trie 
native_client/generate_trie \
    data/alphabet.txt \
    data/lm/lm.binary \
    data/lm/trie_utf8

rm lm.arpa
rm CHAR_GRAMS


########################
### TRAIN DEEPSPEECH ###
########################

mkdir -p ../keep/summaries

python -u DeepSpeech.py \
  --train_files "cv_${_LANG}_valid_train.csv" \
  --dev_files "cv_${_LANG}_valid_dev.csv" \
  --test_files "cv_${_LANG}_valid_test.csv" \
  --train_batch_size 24 \
  --dev_batch_size 48 \
  --test_batch_size 48 \
  --noearly_stop \
  --n_hidden 2048 \
  --learning_rate 0.0001 \
  --dropout_rate 0.2 \
  --epoch 30 \
  --display_step 0 \
  --validation_step 1 \
  --checkpoint_dir "../keep" \
  --summary_dir "../keep/summaries"
