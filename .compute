#!/bin/bash

set -xe

#
#  WARNING - DEV / TEST / TRAIN mixed bcuz zh-TW on server
#

_LANG="cy"
CV="${SHARED_DIR}/data/mozilla/CommonVoice/v2.0-alpha2.0/${_LANG}"

# venv
apt-get install -y python3-venv
python3 -m venv /tmp/venv
source /tmp/venv/bin/activate
# check HTTP_PROXY
if ! (( $( env | grep -iq "^http_proxy=" ) )); then
    source /etc/profile
fi

pip install -r <(grep -v tensorflow requirements.txt)
pip install tensorflow-gpu==1.13.0-rc2
pip install wheel


###############################
### INSTALL KENLM + DECODER ###
###############################

pip install "/data/rw/home/ds_ctcdecoder-0.5.0a1-cp36-cp36m-manylinux1_x86_64.whl"
# pip install $(python util/taskcluster.py --decoder)
# python util/taskcluster.py --arch gpu --target ../tmp/native_client


# kenlm Dependencies
apt-get install -y build-essential cmake libboost-all-dev zlib1g-dev libbz2-dev liblzma-dev libeigen3-dev


###################################
### CREATE ALPHABET / LM / TRIE ###
###################################

# alphabet.txt
python util/check_characters.py \
        -csv "${CV}/cv_${_LANG}_valid_train.csv","${CV}/cv_${_LANG}_valid_train.csv","${CV}/cv_${_LANG}_valid_train.csv" \
        -alpha \
    > data/alphabet.txt

# lm.arpa
# TEXT="${SHARED_DIR}/data/wikipedia/${_LANG}/wiki.txt"
# sed -e 's/\(.\)/\1 /g' <$TEXT >CHAR_GRAMS_ZH_TW
TEXT="/data/rw/home/CHAR_GRAMS_ZH_TW"


/data/rw/home/kenlm/build/bin/lmplz \
    --skip_symbols \
    --order 2 \
    --text "${TEXT}" \
    --arpa lm.arpa

# lm.binary
/data/rw/home/kenlm/build/bin/build_binary \
    -a 255 \
    -q 8 trie \
    lm.arpa \
    data/lm/lm.binary

    # trie
# ../tmp/native_client/generate_trie \
/data/rw/home/generate_trie \
    data/alphabet.txt \
    data/lm/lm.binary \
    data/lm/trie_utf8

rm lm.arpa


########################
### TRAIN DEEPSPEECH ###
########################

mkdir -p ../keep/summaries

python -u DeepSpeech.py \
  --train_files "${CV}/cv_${_LANG}_valid_dev.csv" \
  --dev_files "${CV}/cv_${_LANG}_valid_test.csv" \
  --test_files "${CV}/cv_${_LANG}_valid_train.csv" \
  --train_batch_size 24 \
  --dev_batch_size 48 \
  --test_batch_size 48 \
  --n_hidden 2048 \
  --learning_rate 0.0001 \
  --dropout_rate 0.2 \
  --epoch 1000 \
  --earlystop_nsteps 5 \
  --display_step 0 \
  --validation_step 1 \
  --checkpoint_dir "../keep" \
  --summary_dir "../keep/summaries"
